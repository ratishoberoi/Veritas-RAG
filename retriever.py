import os
import json
import re
from typing import Optional
from dotenv import load_dotenv
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.messages import HumanMessage, AIMessage
from vector_store import load_vector_store

load_dotenv()

SYSTEM_PROMPT = """You are an intelligent Personal Knowledge Base Assistant.
Your job is to answer questions strictly based on the context retrieved from the user's documents.

Rules:
- Answer ONLY using the provided context below.
- If the answer is not in the context, say exactly: "I couldn't find this in your knowledge base."
- Never hallucinate or make up facts.
- Be concise and direct.
- If the answer comes from a specific source, mention it naturally (e.g. "According to the PDF..." or "In the YouTube video...").
- Use the chat history to understand follow-up questions and pronouns like "it", "they", "why", "explain more".
- NEVER use outside knowledge. If you do, you MUST prefix that sentence with [OUTSIDE KNOWLEDGE].

Context:
{context}
"""

EVALUATOR_PROMPT = """You are a strict RAG evaluation judge.

You will be given:
1. A QUESTION asked by the user
2. CONTEXT retrieved from a vector database
3. An ANSWER generated by an AI assistant

Your job is to evaluate the answer and return a JSON object with exactly these fields:
{{
  "context_sufficient": true or false,
  "confidence_score": integer between 0 and 100,
  "hallucination_detected": true only if the answer contains claims NOT in the context AND NOT an "I don't know" response,
  "hallucination_reason": "short explanation or empty string",
  "evaluation_summary": "one sentence summary"
}}

Scoring guide for confidence_score:
- 90-100: Answer is fully supported by context, every claim traceable
- 70-89:  Answer is mostly supported, minor gaps
- 50-69:  Answer is partially supported, some claims unverifiable
- 20-49:  Answer is weakly supported, mostly guessing
- 0-19:   Answer has no support in context, likely hallucinated

QUESTION: {question}

CONTEXT: {context}

ANSWER: {answer}

Return ONLY the JSON object. No explanation, no markdown, no code blocks."""

store = {}


def get_llm(model: str = "llama-3.1-8b-instant") -> ChatGroq:
    api_key = os.getenv("GROQ_API_KEY")
    if not api_key:
        raise ValueError("[Retriever] âŒ GROQ_API_KEY not found in .env")
    return ChatGroq(
        api_key=api_key,
        model_name=model,
        temperature=0,
    )


def format_docs(docs: list) -> str:
    formatted = []
    for i, doc in enumerate(docs):
        source = doc.metadata.get("source", "unknown")
        method = doc.metadata.get("method", "unknown")
        page = doc.metadata.get("page", "")
        title = doc.metadata.get("title", "")

        source_label = f"Source {i+1}"
        if "youtube" in source or method == "groq_whisper":
            source_label += f" [YouTube: {title}]"
        elif source.endswith(".pdf"):
            source_label += f" [PDF: {os.path.basename(source)}"
            if page != "":
                source_label += f", Page {int(page)+1}"
            source_label += "]"

        formatted.append(f"{source_label}:\n{doc.page_content}")

    return "\n\n---\n\n".join(formatted)


def get_session_history(session_id: str) -> ChatMessageHistory:
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    history = store[session_id]
    if len(history.messages) > 20:
        history.messages = history.messages[-20:]
    return history


def evaluate_response(
    question: str,
    context: str,
    answer: str
) -> dict:
    try:
        llm = get_llm()
        eval_prompt = ChatPromptTemplate.from_template(EVALUATOR_PROMPT)
        eval_chain = eval_prompt | llm | StrOutputParser()

        raw = eval_chain.invoke({
            "question": question,
            "context": context,
            "answer": answer
        })

        raw = raw.strip()
        raw = re.sub(r"```json|```", "", raw).strip()

        result = json.loads(raw)

        return {
            "context_sufficient": bool(result.get("context_sufficient", False)),
            "confidence_score": int(result.get("confidence_score", 0)),
            "hallucination_detected": bool(result.get("hallucination_detected", False)),
            "hallucination_reason": result.get("hallucination_reason", ""),
            "evaluation_summary": result.get("evaluation_summary", "")
        }

    except Exception as e:
        print(f"[Evaluator] âš ï¸ Evaluation failed: {e}")
        return {
            "context_sufficient": False,
            "confidence_score": 0,
            "hallucination_detected": False,
            "hallucination_reason": "",
            "evaluation_summary": "Evaluation unavailable."
        }


def build_rag_chain(
    namespace: Optional[str] = None,
    source_filter: Optional[dict] = None
):
    print("[Retriever] ğŸ”„ Building RAG chain with memory...")

    vector_store = load_vector_store(namespace=namespace)

    search_kwargs = {"k": 4}
    if source_filter:
        search_kwargs["filter"] = source_filter
        print(f"[Retriever] ğŸ” Source filter applied: {source_filter}")

    retriever = vector_store.as_retriever(
        search_type="similarity",
        search_kwargs=search_kwargs
    )

    llm = get_llm()

    prompt = ChatPromptTemplate.from_messages([
        ("system", SYSTEM_PROMPT),
        MessagesPlaceholder(variable_name="chat_history"),
        ("human", "{question}")
    ])

    def extract_question(x):
        if isinstance(x, dict):
            return x.get("question", "")
        return str(x)

    core_chain = (
        {
            "context": (lambda x: extract_question(x)) | retriever | format_docs,
            "question": RunnablePassthrough() | (lambda x: extract_question(x)),
            "chat_history": lambda x: x.get("chat_history", []) if isinstance(x, dict) else []
        }
        | prompt
        | llm
        | StrOutputParser()
    )

    chain_with_history = RunnableWithMessageHistory(
        core_chain,
        get_session_history,
        input_messages_key="question",
        history_messages_key="chat_history"
    )

    print("[Retriever] âœ… RAG chain with memory ready.")
    return chain_with_history, retriever


def ask(
    question: str,
    session_id: str = "default",
    namespace: Optional[str] = None,
    source_filter: Optional[dict] = None
) -> dict:
    chain, retriever = build_rag_chain(
        namespace=namespace,
        source_filter=source_filter
    )

    search_kwargs = {"k": 4}
    if source_filter:
        search_kwargs["filter"] = source_filter

    source_docs = retriever.invoke(question)
    context_str = format_docs(source_docs)

    answer = chain.invoke(
        {"question": question},
        config={"configurable": {"session_id": session_id}}
    )

    evaluation = evaluate_response(
        question=question,
        context=context_str,
        answer=answer
    )

    seen = set()
    sources_used = []
    for doc in source_docs:
        source = doc.metadata.get("source", "unknown")
        method = doc.metadata.get("method", "unknown")
        title = doc.metadata.get("title", "")
        page = doc.metadata.get("page", "")

        if source not in seen:
            seen.add(source)
            if method == "groq_whisper" or "youtube" in str(source).lower():
                sources_used.append(f"ğŸ¥ YouTube: {title}")
            else:
                page_info = f", Page {int(float(page))+1}" if page != "" else ""
                sources_used.append(f"ğŸ“„ PDF: {os.path.basename(str(source))}{page_info}")

    return {
        "answer": answer,
        "sources": sources_used,
        "evaluation": evaluation,
        "session_id": session_id
    }


def render_evaluation(evaluation: dict):
    score = evaluation["confidence_score"]
    sufficient = evaluation["context_sufficient"]
    hallucination = evaluation["hallucination_detected"]
    summary = evaluation["evaluation_summary"]
    reason = evaluation["hallucination_reason"]

    if score >= 70 and sufficient and not hallucination:
        status = "âœ… Context Verified"
        bar_color = "ğŸŸ¢"
    elif score >= 40:
        status = "âš ï¸  Moderate Confidence"
        bar_color = "ğŸŸ¡"
    else:
        status = "ğŸ”´ Low Confidence"
        bar_color = "ğŸ”´"

    filled = int(score / 10)
    bar = bar_color * filled + "â¬œ" * (10 - filled)

    print(f"\nğŸ“Š Evaluation:")
    print(f"   Status     : {status}")
    print(f"   Confidence : {bar} {score}%")
    print(f"   Summary    : {summary}")

    if hallucination:
        print(f"   âš ï¸  Hallucination Flag: {reason}")

    if not sufficient:
        print(f"   â„¹ï¸  Context was insufficient for a complete answer.")


if __name__ == "__main__":
    print("\n" + "="*50)
    print("ğŸ§  Personal Knowledge Base â€” Terminal Chat")
    print("   (Memory + Filters + Self-Evaluation)")
    print("="*50)
    print("Commands:")
    print("  'exit'         â†’ Quit")
    print("  'clear'        â†’ Clear chat history")
    print("  'filter pdf'   â†’ Search only PDFs")
    print("  'filter yt'    â†’ Search only YouTube")
    print("  'filter off'   â†’ Remove filter")
    print("  'history'      â†’ Show chat history")
    print("-"*50 + "\n")

    SESSION_ID = "terminal_session"
    active_filter = None

    print("[Retriever] ğŸ”„ Initializing (this may take a few seconds)...")
    try:
        chain, retriever = build_rag_chain(source_filter=active_filter)
    except Exception as e:
        print(f"[Retriever] âŒ Failed to initialize: {e}")
        exit(1)

    print("[Retriever] âœ… Ready!\n")

    while True:
        try:
            filter_label = ""
            if active_filter:
                filter_label = f" [{list(active_filter.values())[0]}]"

            question = input(f"You{filter_label}: ").strip()

            if not question:
                continue

            if question.lower() in ["exit", "quit", "q"]:
                print("ğŸ‘‹ Goodbye!")
                break

            if question.lower() == "clear":
                if SESSION_ID in store:
                    store[SESSION_ID] = ChatMessageHistory()
                print("ğŸ—‘ï¸  Chat history cleared.\n")
                continue

            if question.lower() == "filter pdf":
                active_filter = {"source": "pdf"}
                chain, retriever = build_rag_chain(source_filter=active_filter)
                print("ğŸ” Filter set: PDFs only.\n")
                continue

            if question.lower() == "filter yt":
                active_filter = {"method": "groq_whisper"}
                chain, retriever = build_rag_chain(source_filter=active_filter)
                print("ğŸ” Filter set: YouTube only.\n")
                continue

            if question.lower() == "filter off":
                active_filter = None
                chain, retriever = build_rag_chain(source_filter=None)
                print("ğŸ” Filter removed â€” searching all sources.\n")
                continue

            if question.lower() == "history":
                history = get_session_history(SESSION_ID)
                if not history.messages:
                    print("ğŸ“­ No history yet.\n")
                else:
                    print("\nğŸ“œ Chat History:")
                    for msg in history.messages:
                        role = "You" if isinstance(msg, HumanMessage) else "ğŸ¤–"
                        print(f"  {role}: {msg.content[:120]}...")
                    print()
                continue

            print("\nğŸ¤” Thinking...\n")

            source_docs = retriever.invoke(question)
            context_str = format_docs(source_docs)

            answer = chain.invoke(
                {"question": question},
                config={"configurable": {"session_id": SESSION_ID}}
            )

            print(f"ğŸ¤– Assistant: {answer}")

            history = get_session_history(SESSION_ID)
            turn_count = len([m for m in history.messages if isinstance(m, HumanMessage)])
            print(f"\nğŸ’¬ Memory: {turn_count} turn(s) in session")

            seen = set()
            print("ğŸ“š Sources:")
            for doc in source_docs:
                source = doc.metadata.get("source", "unknown")
                method = doc.metadata.get("method", "unknown")
                title = doc.metadata.get("title", "")
                page = doc.metadata.get("page", "")
                if source not in seen:
                    seen.add(source)
                    if method == "groq_whisper":
                        print(f"  ğŸ¥ YouTube: {title}")
                    else:
                        page_info = f", Page {int(page)+1}" if page != "" else ""
                        print(f"  ğŸ“„ PDF: {os.path.basename(source)}{page_info}")

            print("\nâ³ Evaluating response...")
            evaluation = evaluate_response(question, context_str, answer)
            render_evaluation(evaluation)

            print("\n" + "-"*50 + "\n")

        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ Goodbye!")
            break
        except Exception as e:
            print(f"[Retriever] âŒ Error: {e}\n")
            continue